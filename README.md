# Illegal Logging and Fire Detector

<img src="https://i.ibb.co/4RrNrgx/logo.png">

# Introduction:

Avoid illegal logging in protected areas.

We can find that just in Mexico (my home country) [1] 70 percent of the wood consumed is of illegal origin according to a study carried out by one of the most prestigious universities UNAM (QS ranking # 100).

https://translate.google.com/translate?sl=es&tl=en&u=https://www.dgcs.unam.mx/boletin/bdboletin/2018_173.html

<img src="https://i.ibb.co/YXRmdkN/image.png" >

I’ll  create a system that is capable of recognizing, through Machine Learning the sounds generated by falling trees, chainsaws and human voices in protected areas, thus warning that illegal logging may be occurring.

I especially want a system that can help protect forests and the species that inhabit them.

<img src="https://i.ibb.co/5xvc3Rb/Fores-1.jpg" height="49%" ><img src="https://i.ibb.co/nm2qk9D/Fores-2.jpg" height="49%" >

Most solutions are based on raising awareness, but looking at more dedicated solutions we can find:

TreeTAG is an emerging smartphone-based supply chain traceability system developed by Earth Observation Systems that tracks the location of logs transported from the forest to the mill.

Disadvantages: Very complex system that requires authorized personnel to be manipulated.

Stardust is a dust-like material that can be sprayed onto wood and detected only with a hand-held device. 

Disadvantages: You need to tag manually every tree which is labor intensive and expensive..

# Solution:

The system, will be easily reproducible, energy efficient and powerful thanks to the ML algorithms that will be implemented combined with the cloud services that we will use for deployment.

<img src="https://i.ibb.co/TRcMLMW/ezgif-com-gif-maker-14.gif" width="100%">

With the PSoC 62S2 Wi-Fi BT Pioneer Kit, i will obtain an audio signal which, through SensiML model, we can pass through a neural network. That will tell us if the noise of a saw cutting the trees or human voice in the forest, and MQ135 for fire smoke.

Displaying the information of the events detected in a simple webapp, together with a map which will indicate the position of the event.

## Features:

* Low-power battery consumption (PSoC and LoraWAN).
* High accuracy (thanks to SensiML).
* Easy production at large scale, due to its simplicity.

# Hardware, Software and Services:

## Hardware:

* PSoC™ 62S2 Wi-Fi BT Pioneer Kit. 1x.
  * https://www.infineon.com/cms/en/product/evaluation-boards/cy8ckit-062s2-43012/
* CY8CKIT-028-SENSE. 1x.
  * https://www.infineon.com/cms/en/product/evaluation-boards/cy8ckit-028-sense/
* MQ135 Air Quality Sensor. 1x.
  * https://www.amazon.com/Ximimark-Quality-Hazardous-Detection-Arduino/dp/B07L73VTTY/
* WiFi LoRa 32 (V2.1). 1x.
  * https://heltec.org/project/wifi-lora-32/
* LiPo Battery. 1x.
  * https://www.amazon.com/1000mAh-battery-Rechargeable-Lithium-Connector/dp/B07BTWK13N

## Software:

* ModusToolbox™.
  * https://www.infineon.com/cms/en/design-support/tools/sdk/modustoolbox-software/
* SensiML.
  * https://sensiml.com/
* Data capture lab.
  * https://sensiml.com/products/data-capture-lab/
* Google Colab.
  * https://colab.research.google.com/
* ReactJS.
  * https://reactjs.org/
* OpenLayers Maps.
  * https://openlayers.org/
* Arduino IDE.
  * https://www.arduino.cc/en/software/

## Services:

* AWS IoT.
  * https://aws.amazon.com/iot/
* AWS IAM.
  * https://aws.amazon.com/iam/
* AWS Cognito.
  * https://aws.amazon.com/cognito/
* AWS S3.
  * https://aws.amazon.com/s3/

# Connection Diagram:

## Backend Diagram:

<img src="https://i.ibb.co/wMhs3Xh/Schene-drawio.png">

- Our device connects to the LoraWAN network through WiFi LoRa 32.
- Once in the Helium network, the data is processed in the Helium Console, connecting to the AWS IoT Gateway.
- In our AWS IoT Integration we receive the data sent by the device to a Topic.
- The web page is subscribed to the topic where we are sending the sensor data, and on the page we display the result.

## Hardware Diagram:

<img src="https://i.ibb.co/cDg0DL7/Untitled-Sketch-bb.png">

- The MQ135 sensor is connected to analog pin A7 on the PSoC™ 62S2.
- The WiFi LoRa 32 is connected to pins P9_6 and P9_7 to receive the information from which sensor to the board.

NOTE: The connection details of both diagrams are explained below.

# Capturing Data:

In this section I will explain how to get audio data from the PSoC to the Data capture lab.

## Setting up the PSoC:

First we have to configure the PSoC in data capture mode. Fortunately, the example project within the Modus Toolbox is already configured in audio data capture mode, so you only have to flash it on the device to start capturing data.

<img src="https://i.ibb.co/7jtdjcT/image.png">

Once the device is flashed we will have to open a new project in SensiML with the following configuration for data capture.

<img src="https://i.ibb.co/ssPx0Bt/image.png">

If everything works correctly we can start receiving data and registering it within our project.

Video: Click on the image
[![Capture](https://i.ibb.co/4RrNrgx/logo.png)](https://youtu.be/1NnxkoxOQmY)

## Capturing Data:

In the case of my project, the easiest thing was to record the sound of several chainsaws, people and neutral audio data in order to properly train the model.

NOTE: The captured audios will be in the [SensiML_Data_Capture_Lab](./SensiML_Data_Capture_Lab/).

Video: Click on the image
[![Capture](https://i.ibb.co/4RrNrgx/logo.png)](https://youtu.be/qyJq7049lT8)

## Labeling Data:

In this case, I did the labeling of the following categories for my model.

<img src="https://i.ibb.co/ZMLTgZs/image.png">

The system is capable of detecting the sound of mechanical saws, humanvoice and neutral silence, in order to avoid false alarms of the system.

# SensiML:

These were the specifications for the data in SensiML.

<img src="https://i.ibb.co/YdJmQ91/image.png">

These were the specs of the model's training.

<img src="https://i.ibb.co/TkT5sCx/image.png">

Here the results of the precision of the model against the data used.

<img src="https://i.ibb.co/BHDTwR0/image.png"> 

And finally the specifications of the [Knowledge Pack](Knowledge_Pack.zip) that is in the repository.

<img src="https://i.ibb.co/09NTs9z/image.png">

# Testing Model on PSoC:

In this case you can see in the video how the model works correctly for the detection of human voice and detection of a Chainsaw. We are doing this test by seeing the PSoC serial output.

NOTE: the serial output is at 1000000 baudrate.

<img src="https://i.ibb.co/8myQqLQ/image.png">

Video: Click on the image
[![Capture](https://i.ibb.co/4RrNrgx/logo.png)](https://youtu.be/zllu2-R3VS4)

# PSoC - WiFi-LoRa-32, MQ135 and CY8CKIT-028-SENSE:

## WiFi-LoRa-32:
Our WiFi-LoRa-32 device, in addition to sending the data received from the PSoC to the Helium network, provides power to our entire device since it has a LiPo battery module and a regulated 3.3v.

| PSoC PIN   | WiFi-LoRa-32 PIN |
|------------|------------------|
| 3.3 V      | 3.3 V            |
| GND        | GND              |
| A14 (P9_6) | 21               |
| A15 (P9_7) | 13               |

## MQ135:

The MQ135 sensor is an analog device that detects foreign gases in the environment, such as smoke, alcohol, etc... (some tests will be done with alcohol and not with smoke due to the risk of starting a fire indoors)

Therefore we have to connect it to a specific analog readout pin.

| PSoC PIN   | MQ135 PIN |
|------------|-----------|
| 3.3 V      | 3.3 V     |
| GND        | GND       |
| A7 (P10_7) | AO        |

## CY8CKIT-028-SENSE:

This device is already fully designed to be used with the PSoC, however being able to display images on the screen can be complicated. In the Modus Toolbox example program we can find an example of the Cypress logo for the screen.

<img src="https://i.ibb.co/GQps0yn/image.png">

As we believe that designing all this with just X and _ can be very cumbersome and tiring, we prefer to create a python script that allows us to convert a 128x40 image into an array of data that can be displayed on the screen.

[Colab Notebook](./Image2PSoC.ipynb)

As we can see in the image we only have to upload our image and the program will convert it into an array that can be displayed.

<img src="https://i.ibb.co/fGrqccb/image.png">

We just have to copy and paste the string that the program gives us and that's it.

<img src="https://i.ibb.co/kxbQfHd/image.png">

This is what it will look like once displayed on the screen.

<img src="https://i.ibb.co/THZ3PNx/20220604-194736.jpg">

## All Together:

Once with all the devices connected we have the following circuit.

<img src="https://i.ibb.co/rF6V8hb/20220604-194509.jpg" >

# Data Transmission:

In this section we will explain all the details of the data transmission since we send the POsC data to AWS IoT.

## PSoC to Helium Network:

### Hardware:

The hardware used for this module was a WiFi-LoRa-32.

* WiFi LoRa 32 (V2.1). 1x.
  * https://heltec.org/project/wifi-lora-32/
* LiPo Battery. 1x.
  * https://www.amazon.com/1000mAh-battery-Rechargeable-Lithium-Connector/dp/B07BTWK13N

### Sofware:

The board software will be in the [ESP32_Helium_OTAA](./ESP32_Helium_OTAA/) folder where the Arduino IDE project will be.

<hr>

### **Helium Console new Device**:

We have to create a new device in our Helium console, this can take up to 20 min to start sending data to the console, do wait a little bit.

<img src="https://i.ibb.co/HGkVkts/image.png">

<hr>

### **Configure the credentials in the Helium creds.h file**

Inside the ESP32_Helium_OTAA folder you will have to configure the credentials that we obtained in the previous step.

    uint8_t DevEui[] = { 0xXX, 0xXX, 0xXX, 0xXX, 0xXX, 0xXX, 0xXX, 0xXX };
    uint8_t AppEui[] = { 0xXX, 0xXX, 0xXX, 0xXX, 0xXX, 0xXX, 0xXX, 0xXX }; 
    uint8_t AppKey[] = { 0xXX, 0xXX, 0xXX, 0xXX, 0xXX, 0xXX, 0xXX, 0xXX, 0xXX, 0xXX, 0xXX, 0xXX, 0xXX, 0xXX, 0xXX, 0xXX };

<hr>

### **Set the correct frequency of LoraWAN**

US915 for Mexico, same if your are in the US, check your region please.

<img src="https://i.ibb.co/0Dnbw6R/image.png">

<hr>

### **Serial to LoraWAN Processing**

Every time our device is going to send data to the Helium network, it reads pins 21 and 13 to see the value that the PSoC is reading, because these values are sent every 10 seconds to the network and each one of the messages has a cost in data credits, therefore we are only sending a character that represents the reading.Because the helium network is getting bigger day by day, we can be certain that our devices will have coverage almost anywhere.

| PSoC Detection | Character |
|----------------|-----------|
| Nothing        | '0'       |
| Humans         | '1'       |
| Logging        | '2'       |
| Fire           | '3'       |

<hr>

    case DEVICE_STATE_SEND:
    {
      LoRaWAN.displaySending();
      String test;
      bool human = digitalRead(HUMAN_PIN);
      bool saw = digitalRead(CHAINSAW_PIN);
      if(saw && human){
        test = "3";
      }
      else if(human){
        test = "1";
      }
      else if(saw){
        test = "2";
      }
      else{
        test = "0";
      }
      Serial.print("Human: ");
      Serial.println(human);
      Serial.print("Saw: ");
      Serial.println(saw);
      sendStringData(test);
      deviceState = DEVICE_STATE_CYCLE;
      break;
    }

### Helium Network Coverage:

Because the helium network is getting bigger day by day, we can be certain that our devices will have coverage almost anywhere.

https://explorer.helium.com/

<img src="https://i.ibb.co/NrGfyT1/image.png">

Now as shown here is an example of how our device is sending data to the Helium network.

Video: Click on the image
<img src="https://i.ibb.co/MsMXg3H/image.png">

## Helium Network to AWS IoT:

To communicate the Helium Network platform with AWS IoT, I decided to use the integration that Helium already has developed to avoid setbacks trying to implement my own.

<img src="https://i.ibb.co/nB4Q6dv/image.png">

This integration is based on creating an AWS IAM credential so that the Helium Console can make the corresponding publications in AWS IoT.

<img src="https://i.ibb.co/bBPCWFZ/image.png">

### Backend DEMO:

Here is a demonstration of the entire backend running at the same time.

Video: Click on the image
[![Capture](https://i.ibb.co/4RrNrgx/logo.png)](https://youtu.be/0V7A9kYDo9o)

# WebPage Deploy:

The deployment of the web page was done using ReactJS, OpenLayers (Maps) and AWS-SDK for javascript.

https://illegal-logging-and-fire-detector.s3.amazonaws.com/index.html

<img src="https://i.ibb.co/sHN7Szb/image.png">

## AWS Cognito:

For security, to safely use and consume AWS services, **identity pool** credentials were implemented with the Cognito service.

The access keys for AWSIoT and Cognito must be placed in the following file.

Webapp/src/components/aws-configuration.js

    var awsConfiguration = {
      poolId: "us-east-1:XXXXXXXXXXXXXXX", // 'YourCognitoIdentityPoolId'
      host:"XXXXXXXXXXXXXX-ats.iot.us-east-1.amazonaws.com", // 'YourAwsIoTEndpoint', e.g. 'prefix.iot.us-east-1.amazonaws.com'
      region: "us-east-1" // 'YourAwsRegion', e.g. 'us-east-1'
    };
    module.exports = awsConfiguration;

## AWS IoT WebSocket:

The web page receives the sensor data through AWSIoT as a web socket, so it is important to define within the page, which is the topic that we are going to receive, in this case "/helium/devices" as we could see in the video of [Backend Video](# backend-demo).

In the following file, put the name of the topic to which you will be subscribed.

[WebApp/src/App.js](./WebApp/src/App.js)

    <IotReciever sub_topics={["/helium/devices"]} callback={this.callBackIoT} />

### **Decode IN Data**:

Because the data we receive from Helium Payload is base64 encoding, we need to decode it with the following code in the webapp.

    let temp = {
      name: JSON.parse(data[1]).name,
      payload: atob(JSON.parse(data[1]).payload),
    }

This performs a conversion like the one we see in the image.

<img src="https://i.ibb.co/rwsMbHs/image.png">

Depending on the result of the Payload we will be able to know what situation the device is detecting.

| Detection Kind | Payload   |
|----------------|-----------|
| Nothing        | '0'       |
| Humans         | '1'       |
| Logging        | '2'       |
| Fire           | '3'       |

In turn we can know the type of situation due to the symbol shown on the map.

<img src="https://i.ibb.co/r6Nd5Dg/New-Project-10.png">

# Mini DEMO:

Video: Click on the image
[![Capture](https://i.ibb.co/4RrNrgx/logo.png)](https://youtu.be/SdWnbve8zJ8)

# Final Product:

Case Closed:

<img src="https://i.ibb.co/gtWC3Jb/20220611-142331.jpg">

Case open:

<img src="https://i.ibb.co/CMJW55T/20220611-142714.jpg">

Platform UI:

<img src="https://i.ibb.co/r6Nd5Dg/New-Project-10.png">

Page URL:

https://illegal-logging-and-fire-detector.s3.amazonaws.com/index.html

# EPIC DEMO:

Video: Click on the image
[![demo](https://i.ibb.co/4RrNrgx/logo.png)](https://youtu.be/W7tBl_o99-Q)

Sorry, github does not allow embed videos.
